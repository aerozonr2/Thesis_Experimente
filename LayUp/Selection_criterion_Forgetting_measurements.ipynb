{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59c559aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddaa8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /export/home/0schindl/.netrc\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=\"8a88a8c49d1c2d31b8677fe0b8eb7d3e3a031f83\")\n",
    "api = wandb.Api()\n",
    "fill_value = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "901cc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/wk4w5q0t\"\n",
    "sweep = api.sweep(sweep_id)\n",
    "runs = sweep.runs\n",
    "cil_datasets = [\"cifar100\", \"imagenetr\", \"cub\", \"imageneta\", \"vtab\", \"cars\", \"omnibenchmark\"]\n",
    "dil_datasets = [\"cddb\", \"dil_imagenetr\", \"limited_domainnet\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1d16b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame der Sweep-Runs:\n",
      "      run_id        dataset selection_method  end_task_0/acc  end_task_1/acc  end_task_2/acc  end_task_3/acc  end_task_4/acc  initial_task_2/acc  initial_task_4/acc  initial_task_3/acc  initial_task_0/acc  initial_task_1/acc\n",
      "0   53rkgrjf  omnibenchmark       inv_ws_div        0.723618        0.553512        0.424749        0.715719        0.600000            0.596990            0.676667            0.744147            0.735343            0.607023\n",
      "1   da82toeh           cars       inv_ws_div        0.341829        0.318859        0.207776        0.229858        0.261239            0.317132            0.349939            0.368483            0.422789            0.414392\n",
      "2   as2k8u4j           vtab       inv_ws_div        0.786524        0.772707        0.883538             NaN             NaN            0.901051                 NaN                 NaN            0.818010            0.810443\n",
      "3   923atyey           vtab           around        0.771411        0.780167        0.882662             NaN             NaN            0.913310                 NaN                 NaN            0.806045            0.817903\n",
      "4   kjxo0x09  omnibenchmark           around        0.664992        0.556856        0.433110        0.675585        0.560000            0.596990            0.676667            0.742475            0.737018            0.605351\n",
      "5   kjh5dj04           cars           around        0.361319        0.282878        0.211422        0.225118        0.250304            0.339004            0.349939            0.366114            0.458771            0.403226\n",
      "6   srie9ojl      imageneta           around        0.434211        0.347561        0.431818        0.404255        0.377551            0.522727            0.464286            0.446809            0.519737            0.426829\n",
      "7   kemmqdbx      imageneta       inv_ws_div        0.407895        0.353659        0.465909        0.397163        0.372449            0.522727            0.464286            0.446809            0.519737            0.426829\n",
      "8   qr5u1wcw      imagenetr           around        0.638182        0.664000        0.568627        0.596226        0.535000            0.645098            0.613333            0.656604            0.698182            0.736000\n",
      "9   b0dzsjax            cub       inv_ws_div        0.745614        0.741803        0.687023        0.783410        0.785714            0.770992            0.833333            0.880184            0.846491            0.840164\n",
      "10  zv1t9s88            cub           around        0.745614        0.709016        0.687023        0.764977        0.789683            0.755725            0.825397            0.861751            0.855263            0.827869\n",
      "11  oju7pgkq      imagenetr       inv_ws_div        0.636364        0.666000        0.588235        0.586792        0.491667            0.664706            0.575000            0.635849            0.700000            0.754000\n",
      "12  q9r1xc9a       cifar100       inv_ws_div        0.763000        0.777000        0.644000        0.811000        0.858000            0.721000            0.880000            0.851000            0.811000            0.810000\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "# whats with cddb ???\n",
    "for run in runs:\n",
    "    config = run.config\n",
    "    summary = run.summary\n",
    "    \n",
    "\n",
    "    dataset = config.get(\"dataset\")\n",
    "    selection_method = config.get(\"selection_method\")\n",
    "    run_id = run.id\n",
    "    state = run.state\n",
    "    num_E = config.get(\"moe_max_experts\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if state == \"finished\" and dataset in cil_datasets and (selection_method == \"around\" or selection_method == \"inv_ws_div\"):\n",
    "        # Get the history of the run\n",
    "        history = run.history()\n",
    "\n",
    "        run_data = {\n",
    "            \"run_id\": run_id,\n",
    "            \"dataset\": dataset,\n",
    "            \"selection_method\": selection_method           \n",
    "            }\n",
    "        \n",
    "\n",
    "        # End accuracy of tasks\n",
    "        for key, value in summary.items():\n",
    "            if key.startswith(\"task_\") and key.endswith(\"/acc\") and key != \"task_mean/acc\" and key != \"task_wmean/acc\":\n",
    "                t = int(key.split(\"_\")[1].split(\"/\")[0])\n",
    "\n",
    "                # is an initial task\n",
    "                if num_E <= t:\n",
    "                    continue\n",
    "\n",
    "                key = \"end_\" + key\n",
    "                run_data[key] = value\n",
    "           \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Initial accuracy of tasks\n",
    "        for line in history.items():\n",
    "            key = line[0]\n",
    "            if key.startswith(\"task_\") and key.endswith(\"/acc\") and key != \"task_mean/acc\" and key != \"task_wmean/acc\":\n",
    "                t = int(key.split(\"_\")[1].split(\"/\")[0])\n",
    "\n",
    "                # is an initial task\n",
    "                if num_E <= t:\n",
    "                    continue\n",
    "\n",
    "                values = line[1]\n",
    "                filtered_values = values[~np.isnan(values)]\n",
    "                index = num_E - t - 1\n",
    "                base_acc = filtered_values.iloc[index]\n",
    "                key = \"initial_\" + key\n",
    "                run_data[key] = base_acc\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data.append(run_data)\n",
    "        \n",
    "        \n",
    "df_sweep = pd.DataFrame(data)\n",
    "print(\"\\nDataFrame der Sweep-Runs:\")\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df_sweep)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b353de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame der Sweep-Runs:\n",
      "      run_id        dataset selection_method  end_task_0/acc  end_task_1/acc  end_task_2/acc  end_task_3/acc  end_task_4/acc  initial_task_2/acc  initial_task_4/acc  initial_task_3/acc  initial_task_0/acc  initial_task_1/acc  average_forgetting\n",
      "1   da82toeh           cars       inv_ws_div        0.341829        0.318859        0.207776        0.229858        0.261239            0.317132            0.349939            0.368483            0.422789            0.414392            0.102635\n",
      "5   kjh5dj04           cars           around        0.361319        0.282878        0.211422        0.225118        0.250304            0.339004            0.349939            0.366114            0.458771            0.403226            0.117202\n",
      "12  q9r1xc9a       cifar100       inv_ws_div        0.763000        0.777000        0.644000        0.811000        0.858000            0.721000            0.880000            0.851000            0.811000            0.810000            0.044000\n",
      "9   b0dzsjax            cub       inv_ws_div        0.745614        0.741803        0.687023        0.783410        0.785714            0.770992            0.833333            0.880184            0.846491            0.840164            0.085520\n",
      "10  zv1t9s88            cub           around        0.745614        0.709016        0.687023        0.764977        0.789683            0.755725            0.825397            0.861751            0.855263            0.827869            0.085938\n",
      "6   srie9ojl      imageneta           around        0.434211        0.347561        0.431818        0.404255        0.377551            0.522727            0.464286            0.446809            0.519737            0.426829            0.076998\n",
      "7   kemmqdbx      imageneta       inv_ws_div        0.407895        0.353659        0.465909        0.397163        0.372449            0.522727            0.464286            0.446809            0.519737            0.426829            0.076663\n",
      "8   qr5u1wcw      imagenetr           around        0.638182        0.664000        0.568627        0.596226        0.535000            0.645098            0.613333            0.656604            0.698182            0.736000            0.069436\n",
      "11  oju7pgkq      imagenetr       inv_ws_div        0.636364        0.666000        0.588235        0.586792        0.491667            0.664706            0.575000            0.635849            0.700000            0.754000            0.072099\n",
      "0   53rkgrjf  omnibenchmark       inv_ws_div        0.723618        0.553512        0.424749        0.715719        0.600000            0.596990            0.676667            0.744147            0.735343            0.607023            0.068515\n",
      "4   kjxo0x09  omnibenchmark           around        0.664992        0.556856        0.433110        0.675585        0.560000            0.596990            0.676667            0.742475            0.737018            0.605351            0.093592\n",
      "2   as2k8u4j           vtab       inv_ws_div        0.786524        0.772707        0.883538             NaN             NaN            0.901051                 NaN                 NaN            0.818010            0.810443            0.028912\n",
      "3   923atyey           vtab           around        0.771411        0.780167        0.882662             NaN             NaN            0.913310                 NaN                 NaN            0.806045            0.817903            0.034340\n"
     ]
    }
   ],
   "source": [
    "df_forgetting = df_sweep.copy()\n",
    "\n",
    "# Identify end and initial task accuracy columns\n",
    "end_cols = [col for col in df_sweep.columns if col.startswith('end_task_') and col.endswith('/acc')]\n",
    "initial_cols = [col for col in df_sweep.columns if col.startswith('initial_task_') and col.endswith('/acc')]\n",
    "\n",
    "# Calculate forgetting for each task\n",
    "forgetting_values = []\n",
    "for index, row in df_sweep.iterrows():\n",
    "    row_forgetting = []\n",
    "    for i in range(5):  # Assuming there are tasks 0 to 4\n",
    "        end_col = f'end_task_{i}/acc'\n",
    "        initial_col = f'initial_task_{i}/acc'\n",
    "        if end_col in row and initial_col in row and pd.notna(row[end_col]) and pd.notna(row[initial_col]):\n",
    "            forgetting = row[initial_col] - row[end_col]\n",
    "            row_forgetting.append(forgetting)\n",
    "    # Calculate the average forgetting for the row, ignoring NaNs\n",
    "    avg_forgetting = np.nanmean(row_forgetting)\n",
    "    forgetting_values.append(avg_forgetting)\n",
    "\n",
    "# Add the average forgetting as a new column\n",
    "df_forgetting['average_forgetting'] = forgetting_values\n",
    "\n",
    "print(\"\\nDataFrame der Sweep-Runs:\")\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df_forgetting.sort_values(by='dataset'))\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda99b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d383e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
