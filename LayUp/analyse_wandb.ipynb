{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c559aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddaa8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /export/home/0schindl/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbelaschindler\u001b[0m (\u001b[33mbelaschindler-university-hamburg\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=\"8a88a8c49d1c2d31b8677fe0b8eb7d3e3a031f83\")\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad49df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert_distribution(run):\n",
    "    if run.state != \"finished\":\n",
    "        return None\n",
    "\n",
    "    history = run.history()\n",
    "    \n",
    "    expert_distributions = dict()\n",
    "    ft_tasks = [None] * 1000\n",
    "    ft_buffer = run.config.get(\"moe_max_experts\")\n",
    "    for line in run.history().columns:\n",
    "        if line.startswith(\"Expert\") and line.endswith(\"learned task\"):\n",
    "            \n",
    "            line_splited = line.split(\" \")\n",
    "            expert = int(line_splited[1])\n",
    "            tasks = history[line].dropna().tolist()\n",
    "            tasks = [int(task) for task in tasks]\n",
    "            \n",
    "            if expert not in expert_distributions:\n",
    "                expert_distributions[expert] = list()\n",
    "            expert_distributions[expert].extend(tasks) \n",
    "\n",
    "            \n",
    "            for i in tasks:\n",
    "                if i >= ft_buffer:\n",
    "                    ft_tasks[i - ft_buffer] = expert    \n",
    "\n",
    "    # cleaning ft_tasks\n",
    "    ft_tasks = [i for i in ft_tasks if i is not None]\n",
    "\n",
    "    return ft_tasks, expert_distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901cc94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame der Sweep-Runs:\n",
      "     run_id        dataset selection_method  mean_acc\n",
      "0  f1etfz4c  dil_imagenetr           kl_div  0.035325\n",
      "1  lolfv1ky  dil_imagenetr   inv_eucld_dist  0.042349\n",
      "2  ut9m2ban  dil_imagenetr           ws_div  0.052182\n",
      "3  ccodxf0x  dil_imagenetr       eucld_dist  0.075996\n",
      "4  oh5mrj60  dil_imagenetr           around  0.062176\n"
     ]
    }
   ],
   "source": [
    "sweep_id = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/wk4w5q0t\"\n",
    "sweep = api.sweep(sweep_id)\n",
    "runs = sweep.runs\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    config = run.config\n",
    "    summary = run.summary\n",
    "\n",
    "    dataset = config.get(\"dataset\")\n",
    "    selection_method = config.get(\"selection_method\")\n",
    "    mean_acc = summary.get(\"task_mean/acc\")\n",
    "    run_id = run.id\n",
    "    state = run.state\n",
    "\n",
    "    if dataset is not None and selection_method is not None and mean_acc is not None and state == \"finished\":\n",
    "        data.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"dataset\": dataset,\n",
    "            \"selection_method\": selection_method,\n",
    "            \"mean_acc\": mean_acc\n",
    "            })\n",
    "\n",
    "df_sweep = pd.DataFrame(data)\n",
    "print(\"\\nDataFrame der Sweep-Runs:\")\n",
    "print(df_sweep.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7beed876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Übersicht der Selection Methods nach Dataset:\n",
      "              cars            cddb        cifar100             cub   dil_imagenetr       imageneta       imagenetr limited_domainnet   omnibenchmark            vtab\n",
      "1.          kl_div          around      inv_ws_div      inv_ws_div      eucld_dist      inv_kl_div      inv_kl_div        inv_ws_div      inv_ws_div          kl_div\n",
      "2.      inv_kl_div          ws_div      inv_kl_div          ws_div          around          kl_div          ws_div            around          ws_div      inv_kl_div\n",
      "3.  inv_eucld_dist          kl_div          around      inv_kl_div          ws_div  inv_eucld_dist  inv_eucld_dist            kl_div          around  inv_eucld_dist\n",
      "4.      eucld_dist      inv_kl_div      eucld_dist          kl_div      inv_ws_div      inv_ws_div      eucld_dist    inv_eucld_dist      eucld_dist      inv_ws_div\n",
      "5.          around  inv_eucld_dist          kl_div      eucld_dist  inv_eucld_dist      eucld_dist          around        eucld_dist  inv_eucld_dist          around\n",
      "6.      inv_ws_div      inv_ws_div  inv_eucld_dist  inv_eucld_dist          kl_div      eucld_dist      inv_ws_div            ws_div          kl_div      eucld_dist\n",
      "7.          ws_div      eucld_dist          ws_div          around             NaN          around          kl_div        inv_kl_div      inv_kl_div          ws_div\n"
     ]
    }
   ],
   "source": [
    "fill_value = \"N/A\"  # Hier kannst du deinen gewünschten Füllwert festlegen\n",
    "\n",
    "def rank_selection_methods(group):\n",
    "    \"\"\"Ordnet die Selection Methods innerhalb einer Dataset-Gruppe nach mean_acc.\"\"\"\n",
    "    ranked = group.sort_values(by='mean_acc', ascending=False)['selection_method'].reset_index(drop=True)\n",
    "    return ranked\n",
    "\n",
    "ranked_methods = df_sweep.groupby('dataset').apply(rank_selection_methods)\n",
    "\n",
    "# Erstelle einen neuen DataFrame für die Übersicht mit Füllwerten\n",
    "overview_ranked = pd.DataFrame()\n",
    "max_rows = 0\n",
    "for dataset in ranked_methods.index.get_level_values('dataset').unique():\n",
    "    methods = ranked_methods[dataset]\n",
    "    overview_ranked[dataset] = methods.reindex(range(len(methods)), fill_value=fill_value)\n",
    "    max_rows = max(max_rows, len(methods))\n",
    "\n",
    "# Setze den Index basierend auf der tatsächlichen Anzahl der Zeilen im DataFrame\n",
    "overview_ranked.index = [f\"{i+1}.\" for i in range(len(overview_ranked))]\n",
    "\n",
    "\n",
    "print(\"\\nÜbersicht der Selection Methods nach Dataset:\")\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(overview_ranked)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92103a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Übersicht der Run IDs nach Dataset (sortiert nach mean_acc):\n",
      "        cars      cddb  cifar100       cub dil_imagenetr imageneta imagenetr limited_domainnet omnibenchmark      vtab\n",
      "1.  al08o88u  fw7owkrl  q9r1xc9a  b0dzsjax      ccodxf0x  i456qxf5  e7fey5va          jg82arnp      53rkgrjf  msix6frk\n",
      "2.  fc1z9ff6  sbuithvw  vip27gx3  1v5fru6p      oh5mrj60  f7ho9rvo  9lcro1ez          yantgyei      czo0hmq2  ynjcw7e5\n",
      "3.  ua1ld836  2v1rqtqi  5wzxh6k3  6o4wlyxx      ut9m2ban  kc8w724c  xml5gzh7          3r9p6naq      kjxo0x09  1x3l5agm\n",
      "4.  kvj4knc9  ntbz0it8  4hjczvft  kf6ehova      f9yiptc2  kemmqdbx  b2u56ro8          8iyhagho      5arkgaql  as2k8u4j\n",
      "5.  kjh5dj04  5u5u48j0  p5xo2f0o  iqy2i7z6      lolfv1ky  8ckoklh7  qr5u1wcw          lcpf3ofo      8djuj7se  923atyey\n",
      "6.  da82toeh  ozgume7j  3487s1kp  8asspb0s      f1etfz4c  v58sf8i1  oju7pgkq          xuphq28p      wb55zhl3  yc32vq2v\n",
      "7.  93y21l92  fjt2ri5i  4ww7bxkx  zv1t9s88           NaN  srie9ojl  a9576ypx          gvfz3ds9      otpftybu  aa95bcge\n"
     ]
    }
   ],
   "source": [
    "def rank_run_ids(group):\n",
    "    \"\"\"Ordnet die Run IDs innerhalb einer Dataset-Gruppe nach mean_acc und gibt sie zurück.\"\"\"\n",
    "    ranked_runs = group.sort_values(by='mean_acc', ascending=False)['run_id'].reset_index(drop=True)\n",
    "    return ranked_runs\n",
    "\n",
    "ranked_run_ids_per_dataset = df_sweep.groupby('dataset').apply(rank_run_ids)\n",
    "\n",
    "# Erstelle einen neuen DataFrame für die Übersicht der Run IDs\n",
    "overview_run_ids = pd.DataFrame()\n",
    "max_rows_run_ids = 0\n",
    "for dataset in ranked_run_ids_per_dataset.index.get_level_values('dataset').unique():\n",
    "    run_ids = ranked_run_ids_per_dataset[dataset]\n",
    "    overview_run_ids[dataset] = run_ids.reindex(range(len(run_ids)), fill_value=fill_value)\n",
    "    max_rows_run_ids = max(max_rows_run_ids, len(run_ids))\n",
    "\n",
    "# Setze den Index basierend auf der maximalen Anzahl der Zeilen\n",
    "overview_run_ids.index = [f\"{i+1}.\" for i in range(len(overview_run_ids))]\n",
    "\n",
    "print(\"\\nÜbersicht der Run IDs nach Dataset (sortiert nach mean_acc):\")\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(overview_run_ids)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66801351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Übersicht der Expertenverteilungen nach Dataset (sortiert nach mean_acc):\n",
      "               cars    cddb         cifar100              cub             dil_imagenetr        imageneta        imagenetr limited_domainnet    omnibenchmark    vtab\n",
      "1.  [1, 1, 1, 1, 1]  [0, 1]  [0, 0, 1, 0, 1]  [1, 1, 4, 1, 1]  [1, 1, 1, 1, 1, 1, 1, 1]  [4, 4, 4, 3, 3]  [3, 0, 0, 0, 0]         [2, 0, 0]  [1, 1, 2, 2, 2]  [2, 2]\n",
      "2.  [4, 3, 2, 2, 2]  [1, 2]  [2, 0, 1, 1, 2]  [3, 3, 3, 3, 3]  [0, 1, 2, 3, 4, 5, 6, 0]  [1, 2, 1, 1, 2]  [4, 4, 4, 4, 4]         [0, 1, 2]  [0, 3, 0, 3, 3]  [0, 0]\n",
      "3.  [4, 0, 4, 4, 4]  [2, 2]  [0, 1, 2, 3, 4]  [2, 0, 3, 2, 2]  [5, 1, 1, 1, 1, 1, 1, 1]  [3, 3, 3, 0, 4]  [2, 3, 3, 3, 3]         [2, 2, 2]  [0, 1, 2, 3, 4]  [0, 1]\n",
      "4.  [2, 1, 1, 2, 1]  [0, 1]  [4, 4, 4, 4, 3]  [1, 1, 1, 1, 4]  [3, 6, 2, 0, 5, 3, 3, 3]  [3, 0, 3, 0, 4]  [1, 1, 1, 4, 3]         [2, 2, 2]  [0, 0, 4, 4, 4]  [0, 0]\n",
      "5.  [0, 1, 2, 3, 4]  [2, 1]  [4, 4, 4, 4, 4]  [4, 4, 1, 4, 1]  [3, 6, 3, 3, 4, 4, 3, 3]  [2, 2, 1, 1, 1]  [0, 1, 2, 3, 4]         [1, 1, 0]  [3, 3, 1, 3, 1]  [0, 1]\n",
      "6.  [4, 3, 4, 4, 4]  [2, 0]  [1, 0, 2, 1, 1]  [2, 3, 3, 0, 3]  [4, 5, 5, 6, 5, 5, 5, 6]  [2, 2, 1, 1, 1]  [3, 0, 2, 1, 3]         [1, 1, 1]  [3, 3, 3, 3, 3]  [2, 2]\n",
      "7.  [0, 1, 2, 1, 1]  [0, 2]  [3, 2, 4, 4, 2]  [0, 1, 2, 3, 4]                       N/A  [0, 1, 2, 3, 4]  [1, 1, 4, 1, 1]         [1, 1, 1]  [0, 1, 2, 0, 0]  [2, 1]\n"
     ]
    }
   ],
   "source": [
    "overview_expert_distributions = pd.DataFrame(index=overview_run_ids.index, columns=overview_run_ids.columns)\n",
    "\n",
    "# Iterate through the overview_run_ids DataFrame and call get_expert_distribution for each run\n",
    "for col in overview_run_ids.columns:\n",
    "    for index, run_id in overview_run_ids[col].items():\n",
    "        if pd.notna(run_id):\n",
    "            run = api.run(f\"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/{run_id}\")\n",
    "            expert_distribution = get_expert_distribution(run)[0]\n",
    "            overview_expert_distributions.loc[index, col] = str(expert_distribution)  # Änderung hier: Speichere als String\n",
    "        else:\n",
    "            overview_expert_distributions.loc[index, col] = fill_value\n",
    "\n",
    "print(\"\\nÜbersicht der Expertenverteilungen nach Dataset (sortiert nach mean_acc):\")\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(overview_expert_distributions)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d16b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_DIL = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/6kim8tiu\"\n",
    "sweep_CIL1 = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/p7zmthx9\"\n",
    "sweep_CIL2 = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/jdpa9z1x\"\n",
    "sweep_CIL3 = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/cjddpel4\"\n",
    "sweep_CIL4 = \"belaschindler-university-hamburg/0schindl-LayUp_sweeps_question1_selection_method/hxigp6ck\"\n",
    "\n",
    "\n",
    "sweep = api.sweep(sweep_id)\n",
    "runs = sweep.runs\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    config = run.config\n",
    "    summary = run.summary\n",
    "\n",
    "    dataset = config.get(\"dataset\")\n",
    "    selection_method = config.get(\"selection_method\")\n",
    "    mean_acc = summary.get(\"task_mean/acc\")\n",
    "    run_id = run.id\n",
    "    state = run.state\n",
    "\n",
    "    if dataset is not None and selection_method is not None and mean_acc is not None and state == \"finished\":\n",
    "        data.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"dataset\": dataset,\n",
    "            \"selection_method\": selection_method,\n",
    "            \"mean_acc\": mean_acc\n",
    "            })\n",
    "\n",
    "df_sweep = pd.DataFrame(data)\n",
    "print(\"\\nDataFrame der Sweep-Runs:\")\n",
    "print(df_sweep.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353de03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda99b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d383e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
