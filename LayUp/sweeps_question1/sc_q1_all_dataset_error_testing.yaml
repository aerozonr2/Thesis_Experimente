# Vorgehen:
# 1. "unwichtige" Parameter herausfinden durch Experimente mit num_exp=1 und reduce_dataset=0.25
#     Parameter: Backbone
# 2. Wie 1. aber mut num_exp=5 und reduce_dataset=1 
#     kd, classification, selection_method

program: main.py
method: grid
metric:
  name: 'task_mean/acc'
  goal: maximize
parameters:
  lr:
    values: [0.005]
  dataset:
    values: ["cifar100", "imagenetr", "cub", "dil_imagenetr", "imageneta", "vtab", "cars", "omnibenchmark", "limited_domainnet"]
  finetune_method:
    values: ["vpt"] # SSF braucht andere Python/Modul-Versionen
  finetune_epochs:
    values: [5]
  moe_max_experts:
    values: [5]
  reduce_dataset:
    values: [1]
  T:
    values: [10]
  classification:
    values: ['bayesian']
  backbone:
    values: ["vit_base_patch16_224"]
  sweep_logging:
    values: [True]
  kd:
    values: [False]
  selection_method:
    values: ["kl_div"]