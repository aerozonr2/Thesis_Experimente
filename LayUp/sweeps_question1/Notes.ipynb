{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorgehen:\n",
    "1. beschränktere Parameter herausfinden durch Experimente mit num_exp=1 und reduce_dataset=0.2.\n",
    "    Parameter: Backbone, kd(schhonmal testen)\n",
    "2. Wie 1. aber mit num_exp=3.\n",
    "    Parameter: classification, selection_method\n",
    "- Dadurch schonmal grobe Infos sammeln und dann später stichprobenartig verifizieren\n",
    "\n",
    "3. Mit den gesammelten Infos die Benchmarks übertreffen oder Schonmal Q2 und Q3 anfangen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep: classification_and_selection\n",
    "- reduce_dataset=1.1 statt 0.2:   \n",
    "  \n",
    "|        | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet |\n",
    "|--------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------|\n",
    "| Selection| bayesian | bayesian | bayesian | bayesian | bayesian | bayesian | --- | bayesian | bayesian |\n",
    "| Classification  | inv_ws/inv_kl | ws | inv_eucld | ws | ws | kl/eucld | --- | ws/kl/eucld | inv_ws/(kl) |  \n",
    "\n",
    "- Alt: manche lr/ft_epochs waren immer noch schlecht -> sc_q1_some_datasets_classification_and_selection_get_better_param2 (me5norfz)\n",
    "- Alt: generelle Tests: fj01kgs5, (new 14cyr3rb)\n",
    "- Alt  mit opt lr und ft-epochhs lim_domainnet: sr9avnjp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep: backbone_and_kd\n",
    "- Backbone: nbibpxto, KD: pj12t7ux\n",
    "\n",
    "|               | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet |\n",
    "|---------------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------|\n",
    "| Backbone | egal | in21k | in21k | in21k | (in21k) | normal | --- | normal | normal |  \n",
    "| KD | gleich | gleich | gleich | gleich | gleich | gleich | --- | gleich | <1% |\n",
    "\n",
    "#### KD:\n",
    "Bei cifar100: pj12t7ux nicht klar entscheidbar\n",
    "\n",
    "- Alt: Bessere Parameter herausfinden damit nicht jede acc. 0.1 ist (tp49kob2)\n",
    "- Alt: Cifar: Bei KD alpha hoch machen, da es bis jetzt immer egal ist: (pj12t7ux). Achtung: wenn kd=False ist kd-alpha egal weil es nicht benutzt wird. Habe ich KD richtig implementiert? Evtl aber auch ungünstige andere parameter gewählt, weil oft acc=random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep: lr_ftepoch\n",
    "  \n",
    "|        | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet |\n",
    "|--------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------|\n",
    "| Selection| bayesian | bayesian | bayesian | bayesian | bayesian | bayesian | --- | bayesian | bayesian |\n",
    "| Classification  | inv_ws/inv_kl | ws | inv_eucld | ws | ws | kl/eucld | --- | ws/kl/eucld | inv_ws/(kl) |  \n",
    "\n",
    "- Neu:wie siht der datensatz (domaine oder klassen), wie hsehen die distr. aus. größe des datensatzes und anzahl der images pro klasse. um im vorhinein schon classification auszuwählen. Layup als inspiration. Lr und ft epochs (sollte fest sein) gleich für backbones evtl auch für jeden datensatz (testen mit cifar und dann vtab (klein) und testen ob die lr wirklich so unterschidlich sind)x6p5pa6a und 2ejr8z6d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep qxb0hd5i: sweep_config_batchsize_optimization\n",
    "T=10; moe_max_experts=5; reduce_dataset=1\n",
    "|        | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet | cddb |\n",
    "|--------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------| ---- |\n",
    "| GPU Memory| 7851.74 | 9655.29 | 7228.88 | 9655.29 | 6656.36 | 7486.83 | 7186.94 | 9xxx.xx | --- | --- |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kyra Besprechung:\n",
    "### 25.03.\n",
    "1. Warum ist das Lernen so ungleich verteilt? Was ist das Kriterium für den Vergleich? Welche beiden Werte werden miteinander verglichen und wie kommen sie zu stande?\n",
    "2. Acc.=0 ist Logikfehler. Was wird genau predicted und wie? Wie funktioniert der Prozess? Was ist der output und welche experten werden dabei wie benutzt?\n",
    "3. Wie funktioniert das vergessen und wieviel wird vergessen? Wenn immer nur ein Experte lernt, vergisst er dann wie zu erwarten oder stärkter?\n",
    "4. Random Selection als Vergleich und als Basis. Ich weis da ja definitiv wie der selection Prozess funktioniert, funktioniert denn alles andere wie zu erwarten?\n",
    "5. Wenn die Performance random aussieht wird dann immer die gleiche Klasse predicted oder falsche unterschieldiche?  \n",
    "\n",
    "Generelle Ideen:  \n",
    "- predict_class_bayes vereinfachen und mich nicht zu doll an die SEED-Implementation halten. Einfach eine Liste mit allen Distr. und keine Aufteilung nach Experten. Würde den dim=3 Tensor vereinfachen. Ich muss für den seection Prozess aber Überblick behalten welcher Expert welche Klasse/Distr. gelernt hat.\n",
    "- Man kann evtl. nicht einfach die features des ViTs nehmen sondern nur den ersten (cls?) Token nehmen?\n",
    "- Pseudocode der Funktionen schreiben!! Ist sehr gut für verständniss und späteres beschreiben des Algs.\n",
    "- Werden die distrs. richtig erstellt? was ist mit der symetrie/gespiegelten features in der distr.? whabe ich das noch drin? Da könnte der Fehler sein.\n",
    "\n",
    "#### Selection (Warum wird das wissen so ungleich verteilt?):\n",
    "4. 7s41oxdx angucken und random mit kl_div vergleichen. Wo liegt der fehler? kann ich durch den Vergleich fehlerquellen ausschließen?  \n",
    "--> kurz angeguckt: kl_div ist besser als random, aber ich weiß nicht genau wann oder wieso\n",
    "- kl div: https://wandb.ai/belaschindler-university-hamburg/Test%20project/runs/u89ipbvk/overview\n",
    "- inverted kl div: https://wandb.ai/belaschindler-university-hamburg/Test%20project/runs/bcrcujyc\n",
    "- evtl unnötig, wenn ich die versuche eh unten abgedeckt habe\n",
    "\n",
    "#### Classification:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### klassification aber auch selection (klassification in den Logs):  \n",
    "  moe_max_expert:  \n",
    "    values: [5]  \n",
    "  selection_method:  \n",
    "    values: [\"kl_div\", \"inv_kl_div\"]  \n",
    "  finetune_epochs:  \n",
    "    values: [10]  \n",
    "  lr:  \n",
    "    values: [0.005]  \n",
    "  kl_div_test:  \n",
    "    values: [0, 1, 2]  \n",
    "    \n",
    "Sweep: qubquo0z (alt, wahrscheinlich unnütz), a8ap2jey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
