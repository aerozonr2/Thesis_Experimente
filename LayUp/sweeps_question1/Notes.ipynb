{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorgehen:\n",
    "1. beschränktere Parameter herausfinden durch Experimente mit num_exp=1 und reduce_dataset=0.2.\n",
    "    Parameter: Backbone, kd(schhonmal testen)\n",
    "2. Wie 1. aber mit num_exp=3.\n",
    "    Parameter: classification, selection_method\n",
    "- Dadurch schonmal grobe Infos sammeln und dann später stichprobenartig verifizieren\n",
    "\n",
    "3. Mit den gesammelten Infos die Benchmarks übertreffen oder Schonmal Q2 und Q3 anfangen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep: classification_and_selection\n",
    "- reduce_dataset=1.1 statt 0.2:   \n",
    "  \n",
    "|        | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet |\n",
    "|--------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------|\n",
    "| Selection| bayesian | bayesian | bayesian | bayesian | bayesian | bayesian | --- | bayesian | bayesian |\n",
    "| Classification  | inv_ws/inv_kl | ws | inv_eucld | ws | ws | kl/eucld | --- | ws/kl/eucld | inv_ws/(kl) |  \n",
    "\n",
    "- Alt: manche lr/ft_epochs waren immer noch schlecht -> sc_q1_some_datasets_classification_and_selection_get_better_param2 (me5norfz)\n",
    "- Alt: generelle Tests: fj01kgs5, (new 14cyr3rb)\n",
    "- Alt  mit opt lr und ft-epochhs lim_domainnet: sr9avnjp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep: backbone_and_kd\n",
    "- Backbone: nbibpxto, KD: pj12t7ux\n",
    "\n",
    "|               | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet |\n",
    "|---------------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------|\n",
    "| Backbone | egal | in21k | in21k | in21k | (in21k) | normal | --- | normal | normal |  \n",
    "| KD | gleich | gleich | gleich | gleich | gleich | gleich | --- | gleich | <1% |\n",
    "\n",
    "#### KD:\n",
    "Bei cifar100: pj12t7ux nicht klar entscheidbar\n",
    "\n",
    "- Alt: Bessere Parameter herausfinden damit nicht jede acc. 0.1 ist (tp49kob2)\n",
    "- Alt: Cifar: Bei KD alpha hoch machen, da es bis jetzt immer egal ist: (pj12t7ux). Achtung: wenn kd=False ist kd-alpha egal weil es nicht benutzt wird. Habe ich KD richtig implementiert? Evtl aber auch ungünstige andere parameter gewählt, weil oft acc=random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep: lr_ftepoch\n",
    "  \n",
    "|        | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet |\n",
    "|--------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------|\n",
    "| Selection| bayesian | bayesian | bayesian | bayesian | bayesian | bayesian | --- | bayesian | bayesian |\n",
    "| Classification  | inv_ws/inv_kl | ws | inv_eucld | ws | ws | kl/eucld | --- | ws/kl/eucld | inv_ws/(kl) |  \n",
    "\n",
    "- Neu:wie siht der datensatz (domaine oder klassen), wie hsehen die distr. aus. größe des datensatzes und anzahl der images pro klasse. um im vorhinein schon classification auszuwählen. Layup als inspiration. Lr und ft epochs (sollte fest sein) gleich für backbones evtl auch für jeden datensatz (testen mit cifar und dann vtab (klein) und testen ob die lr wirklich so unterschidlich sind)x6p5pa6a und 2ejr8z6d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep qxb0hd5i: sweep_config_batchsize_optimization\n",
    "T=10; moe_max_experts=5; reduce_dataset=1\n",
    "|        | cifar100 | imagenetr | cub | dil_imagenetr | imageneta | vtab | cars | omnibenchmark | limited_domainnet | cddb |\n",
    "|--------|----------|-----------|-----|--------------|-----------|------|------|--------------|-------------------| ---- |\n",
    "| GPU Memory| 7851.74 | 9655.29 | 7228.88 | 9655.29 | 6656.36 | 7486.83 | 7186.94 | 9xxx.xx | --- | --- |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kyra Besprechung:\n",
    "### 25.03.\n",
    "1. Warum ist das Lernen so ungleich verteilt? Was ist das Kriterium für den Vergleich? Welche beiden Werte werden miteinander verglichen und wie kommen sie zu stande?\n",
    "2. Acc.=0 ist Logikfehler. Was wird genau predicted und wie? Wie funktioniert der Prozess? Was ist der output und welche experten werden dabei wie benutzt?\n",
    "3. Wie funktioniert das vergessen und wieviel wird vergessen? Wenn immer nur ein Experte lernt, vergisst er dann wie zu erwarten oder stärkter?\n",
    "4. Random Selection als Vergleich und als Basis. Ich weis da ja definitiv wie der selection Prozess funktioniert, funktioniert denn alles andere wie zu erwarten?\n",
    "5. Wenn die Performance random aussieht wird dann immer die gleiche Klasse predicted oder falsche unterschieldiche?  \n",
    "\n",
    "Generelle Ideen:  \n",
    "- predict_class_bayes vereinfachen und mich nicht zu doll an die SEED-Implementation halten. Einfach eine Liste mit allen Distr. und keine Aufteilung nach Experten. Würde den dim=3 Tensor vereinfachen. Ich muss für den seection Prozess aber Überblick behalten welcher Expert welche Klasse/Distr. gelernt hat.\n",
    "- Man kann evtl. nicht einfach die features des ViTs nehmen sondern nur den ersten (cls?) Token nehmen?\n",
    "- Pseudocode der Funktionen schreiben!! Ist sehr gut für verständniss und späteres beschreiben des Algs.\n",
    "- Werden die distrs. richtig erstellt? was ist mit der symetrie/gespiegelten features in der distr.? whabe ich das noch drin? Da könnte der Fehler sein.\n",
    "\n",
    "#### Selection (Warum wird das wissen so ungleich verteilt?):\n",
    "4. 7s41oxdx angucken und random mit kl_div vergleichen. Wo liegt der fehler? kann ich durch den Vergleich fehlerquellen ausschließen?  \n",
    "--> kurz angeguckt: kl_div ist besser als random, aber ich weiß nicht genau wann oder wieso\n",
    "- kl div: https://wandb.ai/belaschindler-university-hamburg/Test%20project/runs/u89ipbvk/overview\n",
    "- inverted kl div: https://wandb.ai/belaschindler-university-hamburg/Test%20project/runs/bcrcujyc\n",
    "- evtl unnötig, wenn ich die versuche eh unten abgedeckt habe\n",
    "\n",
    "#### Classification:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### klassification aber auch selection (klassification in den Logs):  \n",
    "  moe_max_expert:  \n",
    "    values: [5]  \n",
    "  selection_method:  \n",
    "    values: [\"kl_div\", \"inv_kl_div\"]  \n",
    "  finetune_epochs:  \n",
    "    values: [10]  \n",
    "  lr:  \n",
    "    values: [0.005]  \n",
    "  kl_div_test:  \n",
    "    values: [0, 1, 2]  \n",
    "    \n",
    "Sweep: qubquo0z (alt, wahrscheinlich unnütz), a8ap2jey  \n",
    "\n",
    "| Acc. | Mean | Min | Max |\n",
    "|--------|----------|-----------|-----|\n",
    "| kl_div| - | + | + |\n",
    "| inv_kl_div | - | + | - |\n",
    "\n",
    "+: > 0.2, -: < 0.1\n",
    "\n",
    "Acc. Graphen sind alle sehr änlich: Erstmal gut (T<=5) und dann schmiert's ab\n",
    "\n",
    "| Finetunung (Auswahl) | Mean | Min | Max |\n",
    "|--------|----------|-----------|-----|\n",
    "| kl_div| 2:1, 4:4 | 0:2, 2:2, 3:1 | 2:5 |\n",
    "| inv_kl_div | 0:4, 3:1 | 4:1, 2:2, 3:2 | 0:2, 1:1, 3:1, 4:1 |\n",
    "\n",
    "Beste Aufteilung: Maximum mit inverse_kl_div: Ich nehme die maximalen Abstände und dann den experten mit dem kleinsten maximalen Abstand  \n",
    "Ist auch sonst gute selection für bessere Aufteilun. Weitere Bestätigung: sweep oxtwsjhw (Viele CUDA Errors)\n",
    "Es korreliert aber nicht mit Acc.\n",
    "\n",
    "\n",
    "| Klassifikation (Auswahl) | Mean | Min | Max |\n",
    "|--------|----------|-----------|-----|\n",
    "| kl_div| Richige Experten | Richige Experten | Richige Experten |\n",
    "| inv_kl_div | Richige Experten | Richtige Experten | Richige Experten |\n",
    "\n",
    "Es werden immer die Experten für die Klassifikation ausgewählt, welche den Task auch gelernt haben. Hier ist also alles richtig.  \n",
    "vtab: ypsvqn17 (5 Experten) wird jedoch immer der falsche ausgewählt. Ab 3 Experten wird immer der dritte für Selection und Classification ausgewählt.  \n",
    "vtab: p5604ebp selection around => gleichmäßige Verteilung der T. => Expert 2 übernimmt wieder gesammte Classification. Daten von T=2 scheinen sehr aus zu sehen wie alle anderen?\n",
    "\n",
    "\n",
    "#### Zusätzlich:\n",
    "- Wenn ein Experte immer wirder benutzt wird passt er sich evtl immer mehr dem Datensatz an und wird deswegen immer wahrschleinlicher für die Classification genutzt, aber ansich ist das kein großes Problem, da meisdoch der richtige Experte ausgewählt wird\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Felhler in Classification Vorgehen:\n",
    "Fragen:  \n",
    "- Warum werden auch Tasks schlechter, obwohl der Experte garnicht angefasst wurde?  \n",
    "Wird der Head vernünftig geswitcht? Funktioniert switch_expert wirklich wie es soll?  \n",
    "Testlauf 1 (klein): 2 Experten und dann kleiner testlauf. Testlauf 2 (groß): Echte Daten und Expertenmenge (evtl. overkill)\n",
    "- Warum wird der Task beim gefinetunten Experten schlechter:  \n",
    "switch_expert?  \n",
    "- Zu starkes forgetting bei alten Tasks der gefintunten Experten?  \n",
    "Die Acc. angucken\n",
    "Run: uxywoac8 hat Expert 2 alle neues Tasks gelern:  \n",
    "-> Tasks 0-3 bleiben dauerhaft gut. Aber auch reduce_Dataset\n",
    "\n",
    "- Geziehlt immer gen gleichen Experten fintunen. bleiben die Tasks davor alle gut? anye6lip + andere: Fast, manchmal übernimmt der Experte, welcher mehr gefintuned wurde etwas von der Classification anderer.  \n",
    "- Macht es einen unterschied ob die Funktionen aufgerufen werden oder nicht? Nein macht es nicht, zumindest nicht im trainloop: a3w17x17 vs v63d9w0z  \n",
    "\n",
    "#### Ab jetzt tests mit num_exp = 2 und gesammten Dataset, weil reduce dataset die ergebnisse verfälscht, aber mit vtab, weil der Datensatz klein ist\n",
    "\n",
    "#### tl6k8tw4: 2 Experten und des wird immer Expert 1 zu finetunen benutzt. Mal gucken was passiert  \n",
    "#### mh9c20d2: 3 Experts:  \n",
    "1. Erstes Finetuning (Task3): Acc.(T3) = 0.0. \n",
    "1. Task der am Anfang von Experten gelernt wurde behält gute Acc.  \n",
    "1. Der Task der davor von anderem Experten gelernt wurde hat deutlich schlechtere Acc.  \n",
    "Gleiches Verhalten mit Index = 2 ??\n",
    "2. Ursprünglicher Task bleibt weiter gut.\n",
    "2. Experte übernimmt 2/3 con Expert2's Klassifizierung  \n",
    "2. Experte Experte übernimmt Klassifikation der folgenden tasks, aber mit Acc = oder fast = 0\n",
    "\n",
    "3. Siehe 2.  \n",
    "\n",
    "#### --> ft_epochs hochstellen = 5 (fht6u6sa)\n",
    "1. Gleich, aber er schnappt jetzt schon Classification von Task 1 weg\n",
    "2. Er übernimmt die Classification von allem.\n",
    "2. Ursprünglicher Task geht auf 0    \n",
    "-> ft_epochs hoch macht alles schlechter\n",
    "\n",
    "\n",
    "#### mh9c20d2 aber mit index = 2\n",
    "1. Experte klaut bisschen Task0 Classification, abder sonst alles gut\n",
    "\n",
    "2. Siehe 1. + Ursprünglicher Task 40%Acc. weg\n",
    "\n",
    "3. Siehe 1. + Ursprünglicher Task 10%Acc. weg\n",
    "\n",
    "#### hp5tfy7l Höhere lr (0.02) und mehr ft_epochs (3), index = 2\n",
    "Idee: Lr sehr hoch machen und nur einen expterten 1 mal finetunen und dann abbrechen und gucken ob nur der Experte schlechter wurde, oder ob noch andere angepasst wurden, exit after T=3.  \n",
    "- Komisch: alles gut, Acc: 87%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "benutzt meine GPU: 9lkoch hab ich versucht zu killen, ging nicht  \n",
    "benutzt 3. GPU und evtl auch meine: 9hlehman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Besprechung 01.04.\n",
    "- Ich weiß jetzt das Kriterium (Average). Wenn man Max nimmt und dann inverse, erhält man wahrscheinlich die beste Verteilung der Tasks auf die Experten.\n",
    "- Cifar100: Tests wurde für Classification immer der richtige Experte Ausgewählt. Die Klassifikation ist dann aber trotzdem (sehr) schlecht.\n",
    "- Vtab: Bei 2 Experten mit around selection: Hä? (nw7i5zmf)\n",
    "1. Auswahl gut, Acc. T1/T2 = 0, aber Expert1(T1) wurde garnicht angefasst\n",
    "2. Auswahl schlecht, Acc. T1/T2 = 0, aber T3 sehr gut \n",
    "3. Auswahl schlechter, Acc. T1/3 = 0,T2 schlecht, T4 ca. random\n",
    "4. Auswahl schlechter, Acc. T1/3 = 0,T2 schlecht, T4 ca. random, T5 sehr gut\n",
    "5. Auswahl schlechter, Acc. T1/3/4/6 = 0, T2/5 schlecht\n",
    "6. Siehe 5. + T7 =65%\n",
    "7. Alles = 0/schlecht außer T0  \n",
    "-> Acc. T0 verhält sich gut, nimmt stetig ab, aber wie zu erwarten  \n",
    "-> Auswahl bei Classification verschiebt sich immer mehr Richtung Expert1\n",
    "- Vtab: Bei 3 Experten mit around selection: Expert 2 übernimmt gesammte Classification (p5604ebp)  \n",
    "Ab 3 Experten immer Expert2 für CLassification ausgewählt (für jeden Task des Runs), egal wer den Task gelernt hat und dann ist die Acc. immer ca. 0.\n",
    "0. Training Expert2: Übernahme gesammter Classification für alle weiteren Tasks\n",
    "1. Acc. T3 ist 44%, obwohl er von E0 gelernt wurde.\n",
    "2. Acc. T4 ist 36%, obwohl er von E1 gelernt wurde.\n",
    "3. Acc. T5 ist 40%, obwohl er von E2 gelernt wurde.\n",
    "3. Acc. T5 ist 40%, obwohl er von E3 gelernt wurde.\n",
    "##### -----\n",
    "- seed rausnehmen\n",
    "- Numerische Probleme (over/underflow)?\n",
    "- Acc. von 0 ist sehr komisch, schlechter als Random geht eigentlich nicht\n",
    "- Was sind die konkreten Zahlen?\n",
    "1. Classification: Auswahl + Eigentliche Werte der Predictions (cifar)\n",
    "2. Training: Abstandsmaße, warum immer wieder der gleicher E (vtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --moe_max_experts 2 --dataset vtab --lr 0.02 --finetune_epochs 3 --selection around --exit_after_T 2 --T 25 --batch_size 64\n",
    "2 Experten, 3 Tasks.  \n",
    "T2 wird richtiger E0 ausgewählt.\n",
    "T1/2 Acc. = 0, warum, das geht eigentlich nicht.  \n",
    "### hab den ersten Fehler!!!  \n",
    "Testing: 13nxga69 hat nur bei cifar 60% geholt.  \n",
    "4sjawej6 E2 übernimmt immernoch alle Classifications. \n",
    "#### These: In T2 ist eine Klasse die allen anderen sehr ähnlich sieht, deswegen wird immer nur E2 ausgewählt.\n",
    "- Wenn --T=25 tritt müsste bei Task 5-8 auftreten (Klasse in Normalem T3 ist anscheinend zu allem am ähnlichsten. Das ist eine der Klassen 11-15)  \n",
    "--> Das problem tritt nicht auf\n",
    "- T:50, E:50: dulcet-snowflake-86 Sehr schlecht\n",
    "- T:50, E:50, exit_after_T:1: Classification von T1 von E0 übernommen\n",
    "1. Generell sind die Log_probs verdächtig niedrig.   \n",
    "Idee: Fehlerquelle: Bei Erstellung der distr. werden die features geflipped (wahrscheinlich für robisteres Modell), habe das jetzt auskommentiert und jetzt ist die Classification besser. Aber eigentlich dürfte das nicht der Fehler sein. ist es auch nicht!  \n",
    "--> Es gibt zum ersten mal eine positive/realistische Prob. mit E3, er übernimmt fälschlicherweise gesammte Classification.  \n",
    "Idee: Fehlerquelle: bei Erstellen der Distr. Test: Erstellen und gleiche Daten durchjagen, gucken ob die Werte hoch sind.  \n",
    "--> Ja sind sie, alle bei ca. 1000.  \n",
    "Idee: wo geht's dazwischen verloren?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
